{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from f110_gym.envs.base_classes import Integrator\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "import sys\n",
    "from f110_gym.envs.f110_env import F110Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reward:\n",
    "    def __init__(self, min_speed=0.5, max_speed=1.8, map_centers=None,track_width = 2.2):\n",
    "        self.min_speed = min_speed\n",
    "        self.max_speed = max_speed\n",
    "        self.set_parameters(map_centers,track_width)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.epsilon = 1e-5\n",
    "        self.distance_travelled = 0\n",
    "\n",
    "        # Centering reward function\n",
    "        self.func = lambda y : 2 * (np.exp(-0.017*y) - 0.5)\n",
    "    \n",
    "    def set_parameters(self,map_centers, track_width):\n",
    "        self.map_centers = map_centers\n",
    "        # Initial point and center that detrmines the position at the start of episode\n",
    "        self.initial_point = np.array([[0, 0]])\n",
    "        self.initial_center_idx , _ = self.__calculate_distance_from_center(self.map_centers,self.initial_point)\n",
    "        self.initial_center = self.map_centers[self.initial_center_idx]\n",
    "\n",
    "        # Race Track parameters\n",
    "        self.distance_between_centers = np.hstack([[0.],np.linalg.norm(self.map_centers[:-1,:]- self.map_centers[1:,:],axis=1)])\n",
    "        self.total_track_length = np.sum(self.distance_between_centers)\n",
    "        self.track_width = track_width\n",
    "\n",
    "    \n",
    "    def __calculate_distance_from_center(self, centers,curr):\n",
    "        distances = np.linalg.norm(centers - curr, axis=1)\n",
    "        idx = np.argmin(distances)\n",
    "        return idx, distances[idx]\n",
    "    \n",
    "    def reset(self, point):\n",
    "        self.distance_travelled = 0\n",
    "        self.initial_point = point\n",
    "        idx , _ = self.__calculate_distance_from_center(self.map_centers,self.initial_point)\n",
    "        self.initial_center_idx = idx\n",
    "        self.initial_center = self.map_centers[self.initial_center_idx]\n",
    "\n",
    "    def exponential_angle(self, angle):\n",
    "        if angle <=90:\n",
    "            return self.func(angle)\n",
    "        return -1\n",
    "    \n",
    "    def progress_reward(self, curr_position, next_position):\n",
    "        distance = np.linalg.norm(curr_position - next_position)\n",
    "        self.distance_travelled += distance\n",
    "        return self.distance_travelled / self.total_track_length\n",
    "\n",
    "    def centering_reward(self, curr_position,next_position):\n",
    "        \n",
    "        position_vector = next_position - curr_position\n",
    "\n",
    "        curr_idx, c = self.__calculate_distance_from_center(self.map_centers,curr_position)\n",
    "        # print(f'Curr position: {curr_position}, Next position: {next_position} with initial center idx: {curr_idx}')\n",
    "\n",
    "        if curr_idx == self.map_centers.shape[0] - 1:\n",
    "            indices = [curr_idx-1,0]\n",
    "        elif curr_idx == 0:\n",
    "            indices = [self.map_centers.shape[0]-1,curr_idx+1]\n",
    "        else:\n",
    "            indices = [curr_idx-1, curr_idx+1]\n",
    "            \n",
    "        # print(f'Indices: {indices}')\n",
    "        # print(np.vstack([self.map_centers[indices[0],:],self.map_centers[indices[1],:]]))\n",
    "\n",
    "        next_idx, n = self.__calculate_distance_from_center(np.vstack([self.map_centers[indices[0],:],self.map_centers[indices[1],:]]),next_position)\n",
    "        next_idx = indices[next_idx]\n",
    "        # print(f'Next index is {next_idx} and distance is {n}')\n",
    "\n",
    "        curr_center = self.map_centers[curr_idx]\n",
    "        next_center = self.map_centers[next_idx]\n",
    "\n",
    "        if curr_idx == next_idx:\n",
    "            return -1\n",
    "        \n",
    "        # print(f'Current center: {curr_center}, Next center: {next_center}')\n",
    "        center_vector = next_center - curr_center\n",
    "        \n",
    "        dot_product = np.dot(center_vector, position_vector)\n",
    "        norm_product = np.linalg.norm(center_vector) * np.linalg.norm(position_vector)\n",
    "        cosine_angle = dot_product / norm_product\n",
    "        angle_rad = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "\n",
    "        # print(f'Center vector: {center_vector} and Position vector: {position_vector}')\n",
    "\n",
    "        return self.exponential_angle(np.degrees(angle_rad))\n",
    "    \n",
    "    def milestone_reward(self, next_position):\n",
    "        idx, _ = self.__calculate_distance_from_center(self.map_centers,next_position)\n",
    "        if idx!=self.initial_center_idx:\n",
    "            travelled = np.linalg.norm(self.initial_center - next_position) / self.total_track_length\n",
    "            if  travelled >= np.abs(self.distance_between_centers[idx] - self.distance_between_centers[self.initial_center_idx]) / self.total_track_length :\n",
    "                self.initial_center_idx = idx\n",
    "                self.initial_center = self.map_centers[idx]\n",
    "                return 5\n",
    "        return 0\n",
    "    \n",
    "    def calculate_reward(self, curr_position, next_position):\n",
    "        progress_reward = self.progress_reward(curr_position, next_position)\n",
    "        centering_reward = self.centering_reward(curr_position, next_position)\n",
    "        milestone_reward = self.milestone_reward(next_position)\n",
    "        # print(f\"Distance reward: {progress_reward}, Centering reward: {centering_reward}, Milestone reward: {milestone_reward}\")\n",
    "        return progress_reward + centering_reward + milestone_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexSelector:\n",
    "    def __init__(self, num_indices):\n",
    "        self.set_parameters(num_indices)\n",
    "    \n",
    "    def set_parameters(self, num_indices):\n",
    "        self.num_indices = num_indices\n",
    "        self.visited_indices = set()\n",
    "        self.probabilities = np.ones(num_indices) / num_indices\n",
    "    \n",
    "    def select_index(self):\n",
    "        if len(self.visited_indices) == self.num_indices:\n",
    "            # Reset the probabilities and visited indices\n",
    "            print('Visited all indices, resetting')\n",
    "            self.visited_indices = set()\n",
    "            self.probabilities = np.ones(self.num_indices) / self.num_indices\n",
    "\n",
    "        # Select an index based on the current probabilities\n",
    "        random_idx = np.random.choice(np.arange(self.num_indices), p=self.probabilities)\n",
    "\n",
    "        # Update the probabilities\n",
    "        self.visited_indices.add(random_idx)\n",
    "        if len(self.visited_indices) < self.num_indices:\n",
    "            self.probabilities[random_idx] = 0\n",
    "            remaining_prob = 1 - np.sum(self.probabilities)\n",
    "            self.probabilities[self.probabilities > 0] += remaining_prob / np.sum(self.probabilities > 0)\n",
    "\n",
    "        return random_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Tenth_navigation:\n",
    "\n",
    "    def __init__(self,gym_env_code='f110_gym:f110-v0', num_agents=1, map_path=['./f1tenth_racetracks/Austin/Austin_map'], map_ext='.png', sx=0., sy=0., stheta=0., map_centers_file=None, save_path=None, track_name=None, inference=None,reward_file=None,collision_file=None):\n",
    "\n",
    "        # Environment setup\n",
    "        self.path_counter = 0\n",
    "        self.sx, self.sy, self.stheta = sx, sy, stheta\n",
    "        self.save_path = save_path\n",
    "        self.track_name = track_name\n",
    "        self.num_agents = num_agents\n",
    "        self.map_path = map_path\n",
    "        self.map_ext = map_ext\n",
    "        self.map_centers_file = map_centers_file\n",
    "    \n",
    "        self.env = gym.make(gym_env_code, map=self.map_path[self.path_counter], map_ext=self.map_ext, num_agents=self.num_agents, timestep=0.01, integrator=Integrator.RK4)\n",
    "        self.env.add_render_callback(self.render_callback)\n",
    "       \n",
    "        file = pd.read_csv(self.map_centers_file[self.path_counter])\n",
    "        file.columns = ['x', 'y', 'w_r', 'w_l']\n",
    "        file.index = file.index.astype(int)\n",
    "        self.map_centers = file.values[:, :2]\n",
    "        self.track_width = file.loc[0,'w_r'] + file.loc[0,'w_l']\n",
    "        self.reward_file = reward_file\n",
    "        self.collision_file = collision_file\n",
    "\n",
    "        # Random Seed\n",
    "        self.random_seed = 42\n",
    "        np.random.seed(self.random_seed)\n",
    "\n",
    "        # Environment Observation Parameters\n",
    "        self.num_beams = 1080\n",
    "        self.n_features = 11\n",
    "        self.angle = 270\n",
    "\n",
    "        # Action Space Parameters\n",
    "        self.num_angles = 30\n",
    "        self.num_speeds = 10\n",
    "\n",
    "        # LiDAR downsampling parameters\n",
    "        self.n_sectors = 30\n",
    "        self.normalized_lidar = np.zeros((1,self.n_sectors))\n",
    "\n",
    "        # State Space Parameters\n",
    "        self.num_states = 2 ** self.n_features\n",
    "\n",
    "        # Speed Parameters\n",
    "        self.min_speed = 0.8\n",
    "        self.max_speed = 2\n",
    "\n",
    "        # Action Space\n",
    "        self.angles_deg = np.linspace(-self.angle // 2, self.angle // 2, self.num_angles)[::-1]\n",
    "        self.angles = np.radians(self.angles_deg)\n",
    "        self.speeds = np.linspace(self.min_speed, self.max_speed, self.num_speeds)\n",
    "    \n",
    "        # State Space - Q-Table\n",
    "        if inference is not None:\n",
    "            self.weights = np.load(inference)\n",
    "            self.num_collisions = int(inference.split('_')[-1].split('.')[0])\n",
    "            print(f'Loaded Weights')\n",
    "        else:\n",
    "            self.weights = np.zeros((self.num_states,self.num_angles,self.num_speeds))\n",
    "            self.num_collisions = 0\n",
    "\n",
    "        # ELigibility Trace\n",
    "        self.ET_IS = np.zeros((self.num_states,self.num_angles,self.num_speeds))\n",
    "\n",
    "        # projection matrix\n",
    "        if self.n_features == 10:\n",
    "            zero_prob = 0.85\n",
    "            one_prob = 0.15\n",
    "        if self.n_features == 11:\n",
    "            zero_prob = 0.8\n",
    "            one_prob = 0.2\n",
    "        self.projection_matrix = self.get_projection_matrix(zero_prob=zero_prob,one_prob=one_prob)\n",
    "\n",
    "        # binary powers\n",
    "        self.binary_powers = np.array([2 ** i for i in range(self.n_features)])\n",
    "\n",
    "        # Training Variables\n",
    "        self.curr_state = None\n",
    "        self.next_state = None\n",
    "        \n",
    "        self.action_threshold_decay = 0.99997\n",
    "        self.action_threshold = 0.20 * (self.action_threshold_decay ** self.num_collisions)\n",
    "\n",
    "        # Imported Classes\n",
    "        self.reward_class = Reward(min_speed=self.min_speed, max_speed=self.max_speed, map_centers=self.map_centers, track_width=self.track_width)\n",
    "        self.index_selector = IndexSelector(self.map_centers.shape[0])      \n",
    "\n",
    "        # BTSP Parameters\n",
    "        self.learning_rate = 0.1\n",
    "        self.discount_factor = 0.95\n",
    "        self.decay_rate = 0.9\n",
    "\n",
    "        # Reward\n",
    "        self.reward = 0\n",
    "        self.episode_reward = 0\n",
    "        self.cumulative_reward = 0\n",
    "        self.episodic_rewards = [0]\n",
    "        self.delayed_reward = 0\n",
    "        self.delayed_reward_counter = 0\n",
    "\n",
    "        # Time\n",
    "        self.collision_times = [0]       \n",
    "\n",
    "\n",
    "    def __update_map(self):\n",
    "        if self.env.renderer is not None:\n",
    "            self.env.renderer.close()\n",
    "        self.path_counter += 1\n",
    "        if self.path_counter == len(self.map_path):\n",
    "            self.path_counter = 0\n",
    "        self.env.map_name = self.map_path[self.path_counter]\n",
    "        self.env.update_map(f'{self.map_path[self.path_counter]}.yaml',self.map_ext)\n",
    "        F110Env.renderer = None\n",
    "        file = pd.read_csv(self.map_centers_file[self.path_counter])\n",
    "        file.columns = ['x', 'y', 'w_r', 'w_l']\n",
    "        file.index = file.index.astype(int)\n",
    "        self.map_centers = file.values[:, :2]\n",
    "        self.track_width = file.loc[0,'w_r'] + file.loc[0,'w_l']\n",
    "        print(f'Map updated to {self.track_name[self.path_counter]}')\n",
    "        \n",
    "        \n",
    "    def render_callback(self, env_renderer):\n",
    "        e = env_renderer\n",
    "        x = e.cars[0].vertices[::2]\n",
    "        y = e.cars[0].vertices[1::2]\n",
    "        top, bottom, left, right = max(y), min(y), min(x), max(x)\n",
    "        e.score_label.x = left\n",
    "        e.score_label.y = top - 700\n",
    "        e.left = left - 800\n",
    "        e.right = right + 800\n",
    "        e.top = top + 800\n",
    "        e.bottom = bottom - 800\n",
    "\n",
    "\n",
    "    def get_statistical_properties(self,lidar_input,n_sectors=30):\n",
    "        sector_size = np.asarray(lidar_input).shape[0] // n_sectors\n",
    "        sectors = lidar_input[:sector_size * n_sectors].reshape(n_sectors, sector_size)\n",
    "        return np.median(sectors, axis=1).reshape(1,-1)\n",
    "    \n",
    "\n",
    "    def binarize_vector(self,vector):\n",
    "        threshold = (np.min(vector)+ np.max(vector))/2\n",
    "        return np.where(vector > threshold, 1, 0)\n",
    "    \n",
    "\n",
    "    def get_projection_matrix(self,zero_prob=0.5,one_prob=0.5):\n",
    "        # Generate a random matrix with values 0 and 1 based on the given probabilities [prob_0,prob_1]\n",
    "        if not os.path.exists('Projection_matrices'):\n",
    "            os.mkdir('Projection_matrices')\n",
    "        if not os.path.exists(os.path.join('Projection_matrices', f'projection_{self.n_features}f_s{self.random_seed}.npy')):\n",
    "            matrix = np.random.choice([0, 1], size=(self.n_sectors, self.n_features), p=[zero_prob,one_prob])\n",
    "            np.save(os.path.join('Projection_matrices', f'projection_{self.n_features}f_s{self.random_seed}.npy'), matrix)\n",
    "        else:\n",
    "            matrix = np.load(os.path.join('Projection_matrices', f'projection_{self.n_features}f_s{self.random_seed}.npy'))\n",
    "        return matrix\n",
    "    \n",
    "    def softmax(self,x, temperature=3.0):\n",
    "        e_x = np.exp(x  / temperature) \n",
    "        return e_x / e_x.sum(axis=-1)\n",
    "\n",
    "    def get_binary_representation(self,lidar_input):\n",
    "        self.normalized_lidar = normalize(lidar_input,axis=1)\n",
    "        return self.binarize_vector(np.dot( self.normalized_lidar,self.projection_matrix))\n",
    "    \n",
    "\n",
    "    def get_state(self, binary):\n",
    "        return np.dot(binary[0], self.binary_powers)\n",
    "    \n",
    "\n",
    "    def select_action(self, state):\n",
    "        random_number = np.random.rand()\n",
    "        if random_number < self.action_threshold:\n",
    "            angle_index = np.random.randint(0, self.num_angles)\n",
    "            speed_index = np.random.randint(0, self.num_speeds)\n",
    "        else:\n",
    "            max_value = np.max(self.weights[state])\n",
    "            max_indices = np.argwhere(self.weights[state] == max_value)\n",
    "            angle_index, speed_index  = max_indices[np.random.randint(len(max_indices))]\n",
    "\n",
    "        self.action_threshold *= self.action_threshold_decay\n",
    "\n",
    "        return angle_index, speed_index\n",
    "\n",
    "    def select_action_inference(self, state):\n",
    "        max_indices = np.argwhere(self.weights[state] == np.max(self.weights[state]))\n",
    "        angle_index, speed_index  = max_indices[np.random.randint(len(max_indices))]\n",
    "        return angle_index, speed_index\n",
    "\n",
    "    def sarsa_weight_update(self,angle_idx,speed_idx,reward):\n",
    "        next_angle_idx,next_speed_idx = self.select_action(self.next_state)\n",
    "        delta = reward + self.discount_factor * self.weights[self.next_state,next_angle_idx,next_speed_idx] - self.weights[self.curr_state,angle_idx,speed_idx]\n",
    "\n",
    "        self.weights += self.learning_rate * delta * self.ET_IS\n",
    "        return next_angle_idx,next_speed_idx\n",
    "\n",
    "    def set_eligibility_trace(self,angle_idx,speed_idx):\n",
    "        self.ET_IS [self.curr_state,angle_idx,speed_idx] = 1\n",
    "\n",
    "    def decay_eligibility_trace(self):\n",
    "        self.ET_IS *= self.discount_factor * self.decay_rate\n",
    "\n",
    "    def save_reward_time(self):\n",
    "        if not os.path.exists(os.path.join(self.save_path)):\n",
    "            os.mkdir(os.path.join(self.save_path))\n",
    "        \n",
    "        if self.reward_file is not None:\n",
    "            r = np.append(np.load(self.reward_file), self.episodic_rewards)\n",
    "            t = np.append(np.load(self.collision_file), self.collision_times)\n",
    "            np.save(os.path.join(self.save_path, f'rewards.npy'), np.array(r))\n",
    "            np.save(os.path.join(self.save_path, f'times.npy'), np.array(t))\n",
    "        else:\n",
    "            np.save(os.path.join(self.save_path, f'rewards.npy'), np.array(self.episodic_rewards))\n",
    "            np.save(os.path.join(self.save_path, f'times.npy'), np.array(self.collision_times))\n",
    "\n",
    "    def save_weights(self):\n",
    "        if not os.path.exists(os.path.join(self.save_path)):\n",
    "            os.mkdir(os.path.join(self.save_path))\n",
    "        np.save(os.path.join(self.save_path, f'{self.track_name[self.path_counter]}_{self.num_collisions + 1}.npy'), self.weights)\n",
    "        # print(f'File saved')\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        try:\n",
    "            obs, step_reward, done, info = self.env.reset(np.array([[self.sx, self.sy, self.stheta]]))\n",
    "            lidar = obs['scans'][0]\n",
    "            lidar_down_sampled = self.get_statistical_properties(lidar)\n",
    "            self.curr_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "            self.reward_class.reset(np.array([[self.sx, self.sy]]))\n",
    "            angle_index,speed_index = self.select_action(self.curr_state)\n",
    "            start_time = time.time()\n",
    "            while True:\n",
    "                # np.save(f'./LiDAR_scans/scan_{self.curr_state}.npy',lidar)\n",
    "                steering_angle,speed = self.angles[angle_index],self.speeds[speed_index]\n",
    "                curr_x = obs['poses_x'][0]\n",
    "                curr_y = obs['poses_y'][0]\n",
    "                obs, reward, done, info = self.env.step(np.array([[steering_angle, speed]]))\n",
    "                lidar = obs['scans'][0]\n",
    "                lidar_down_sampled = self.get_statistical_properties(lidar)\n",
    "                self.next_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "\n",
    "                if done:\n",
    "                    self.reward =-50\n",
    "                else:           \n",
    "                    self.reward = self.reward_class.calculate_reward(np.array([curr_x, curr_y]), np.array([obs['poses_x'][0], obs['poses_y'][0]]))\n",
    "                \n",
    "                self.episode_reward += self.reward\n",
    "                # self.delayed_reward += self.reward\n",
    "\n",
    "                self.set_eligibility_trace(angle_index,speed_index)\n",
    "                \n",
    "                # if self.delayed_reward_counter == 5:\n",
    "                #     angle_index,speed_index = self.sarsa_weight_update(angle_index,speed_index,self.delayed_reward)\n",
    "                #     self.delayed_reward_counter = 0\n",
    "                #     self.delayed_reward = 0\n",
    "                # else:\n",
    "                #     self.delayed_reward_counter += 1\n",
    "                #     angle_index,speed_index = self.sarsa_weight_update(angle_index,speed_index,0)\n",
    "\n",
    "                angle_index,speed_index = self.sarsa_weight_update(angle_index,speed_index,self.reward)\n",
    "                self.decay_eligibility_trace()\n",
    "                self.curr_state = self.next_state\n",
    "\n",
    "                # Randomize the starting point after collision\n",
    "                if done:\n",
    "                    self.episodic_rewards.append(self.episode_reward)\n",
    "                    self.episode_reward = 0\n",
    "                    end_time = time.time()\n",
    "                    self.collision_times.append(end_time - start_time)\n",
    "                    start_time = end_time\n",
    "\n",
    "                    self.num_collisions += 1\n",
    "                    self.ET_IS.fill(0)\n",
    "\n",
    "                    # Obtaining a new random position on the track\n",
    "                    random_idx = self.index_selector.select_index()\n",
    "                    n_x, n_y = self.map_centers[random_idx]\n",
    "                    delta_x, delta_y = np.random.uniform(-0.75, 0.75), np.random.uniform(-0.2, 0.2)\n",
    "                    n_theta = np.random.choice(self.angles)\n",
    "\n",
    "                    # Sensing the new state\n",
    "                    obs, step_reward, done, info = self.env.reset(np.array([[n_x + delta_x, n_y + delta_y, n_theta]]))\n",
    "                    lidar = obs['scans'][0]\n",
    "                    lidar_down_sampled = self.get_statistical_properties(lidar)\n",
    "                    self.curr_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "                    angle_index,speed_index = self.select_action(self.curr_state)\n",
    "\n",
    "                    # Resetting \n",
    "                    self.reward_class.reset(np.array([[n_x + delta_x, n_y + delta_y]]))\n",
    "                    \n",
    "                    # Checkpoint\n",
    "                    if (self.num_collisions+1) % 1000 == 0:\n",
    "                        print(f'Collision: {self.num_collisions+1}, Time: {sum(self.collision_times)}, Reward: {sum(self.episodic_rewards)}')\n",
    "                        self.save_reward_time()\n",
    "                        self.save_weights()\n",
    "                        self.episodic_rewards.clear()\n",
    "                        self.collision_times.clear()\n",
    "                        self.reward_file = os.path.join(self.save_path, f'rewards.npy')\n",
    "                        self.collision_file = os.path.join(self.save_path, f'times.npy')\n",
    "                        \n",
    "                    if (self.num_collisions+1)  % 2000 == 0:\n",
    "                        print(f'Training on {self.track_name[self.path_counter]} Completed')\n",
    "                        self.__update_map()\n",
    "                        self.reward_class.set_parameters(self.map_centers,self.track_width)\n",
    "                        self.reward_class.reset(np.array([[self.sx, self.sy]]))\n",
    "                        self.env.reset(np.array([[self.sx, self.sy, self.stheta]]))\n",
    "                        self.index_selector.set_parameters(self.map_centers.shape[0])\n",
    "                \n",
    "                # self.env.render(mode='human')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            self.env.renderer.close()\n",
    "            # self.env.renderer = None\n",
    "            self.env.close()\n",
    "        finally:\n",
    "            del self.env\n",
    "\n",
    "    def inference(self):\n",
    "        obs, step_reward, done, info = self.env.reset(np.array([[self.sx, self.sy, self.stheta]]))\n",
    "        lidar = obs['scans'][0]\n",
    "        lidar_down_sampled = self.get_statistical_properties(lidar)\n",
    "        self.curr_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "        self.reward_class.reset(np.array([[self.sx, self.sy]]))\n",
    "        angle_index,speed_index = self.select_action_inference(self.curr_state)\n",
    "        while not done:\n",
    "            steering_angle,speed = self.angles[angle_index],self.speeds[speed_index]\n",
    "            obs, reward, done, info = self.env.step(np.array([[steering_angle, speed]]))\n",
    "            lidar = obs['scans'][0]\n",
    "            lidar_down_sampled = self.get_statistical_properties(lidar)\n",
    "            self.next_state = self.get_state(self.get_binary_representation(lidar_down_sampled))\n",
    "            angle_index,speed_index = self.select_action_inference(self.next_state)\n",
    "            self.curr_state = self.next_state\n",
    "            \n",
    "            self.env.render(mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Oschersleben', 739),\n",
       " ('Spielberg', 864),\n",
       " ('BrandsHatch', 781),\n",
       " ('MoscowRaceway', 813),\n",
       " ('Monza', 1159),\n",
       " ('Mexico City', 860),\n",
       " ('Sakhir', 1082),\n",
       " ('Austin', 1102),\n",
       " ('Budapest', 876),\n",
       " ('Melbourne', 1060),\n",
       " ('Sochi', 1169),\n",
       " ('SaoPaulo', 862),\n",
       " ('Montreal', 872),\n",
       " ('Nuerburgring', 1029),\n",
       " ('Hockenheim', 914),\n",
       " ('Shanghai', 1090),\n",
       " ('Sepang', 1108),\n",
       " ('YasMarina', 1110),\n",
       " ('Catalunya', 931),\n",
       " ('Zandvoort', 864),\n",
       " ('Spa', 1401),\n",
       " ('Silverstone', 1178)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './f1tenth_racetracks'\n",
    "all_map_paths=[]\n",
    "map_centers = []\n",
    "map_names = []\n",
    "track_lengths=[]\n",
    "for folder in os.listdir(path):\n",
    "    if folder not in ['README.md','.gitignore','convert.py','LICENSE','rename.py','.git']:\n",
    "        folder_name=folder\n",
    "        file_name=folder_name.replace(' ','')+'_map'\n",
    "        map_center = folder_name.replace(' ','')+'_centerline.csv'\n",
    "        track_lengths.append(len(pd.read_csv(f'{path}/{folder_name}/{map_center}')))\n",
    "        map_names.append(folder_name)\n",
    "        all_map_paths.append(f'{path}/{folder_name}/{file_name}')\n",
    "        map_centers.append(f'{path}/{folder_name}/{map_center}')\n",
    "\n",
    "track_length_list = list(zip(map_names,track_lengths))\n",
    "track_length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Maps: ['MoscowRaceway', 'YasMarina', 'Sepang', 'Austin', 'Melbourne', 'Mexico City', 'Monza', 'Silverstone', 'Spa']\n",
      "Test Maps: ['Oschersleben', 'Spielberg', 'BrandsHatch', 'Sakhir', 'Budapest', 'Sochi', 'SaoPaulo', 'Montreal', 'Nuerburgring', 'Hockenheim', 'Shanghai', 'Catalunya', 'Zandvoort']\n"
     ]
    }
   ],
   "source": [
    "train_maps = ['MoscowRaceway','YasMarina','Sepang','Austin','Melbourne','Mexico City','Monza','Silverstone','Spa']\n",
    "test_maps = [i[0] for i in track_length_list if i[0] not in train_maps]\n",
    "print(f'Train Maps: {train_maps}')\n",
    "print(f'Test Maps: {test_maps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/f1tenth_gym/gym/f110_gym/envs/base_classes.py:93: UserWarning: Chosen integrator is RK4. This is different from previous versions of the gym.\n",
      "  warnings.warn(f\"Chosen integrator is RK4. This is different from previous versions of the gym.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visited all indices, resetting\n",
      "Collision: 1000, Time: 259.8837375640869, Reward: -94723.72116566692\n",
      "Visited all indices, resetting\n",
      "Collision: 2000, Time: 321.93824100494385, Reward: -90055.10453426259\n",
      "Training on MoscowRaceway Completed\n",
      "Map updated to Monza\n",
      "Collision: 3000, Time: 476.4615738391876, Reward: -58751.43249443645\n",
      "Visited all indices, resetting\n",
      "Collision: 4000, Time: 444.9024968147278, Reward: -68651.08235076038\n",
      "Training on Monza Completed\n",
      "Map updated to Mexico City\n",
      "Visited all indices, resetting\n",
      "Collision: 5000, Time: 819.9105112552643, Reward: -1395.3714991676497\n",
      "Visited all indices, resetting\n",
      "Collision: 6000, Time: 467.29459595680237, Reward: -73633.60422738781\n",
      "Training on Mexico City Completed\n",
      "Map updated to Austin\n"
     ]
    }
   ],
   "source": [
    "global num_agents,map_path,map_ext,sx,sy,stheta,num_maps_to_train,gym_env_code,inference_file,reward_file,collision_file,counter,indices,save_path\n",
    "gym_env_code='f110_gym:f110-v0'\n",
    "num_agents = 1\n",
    "map_ext = '.png'\n",
    "sx = 0.\n",
    "sy = 0.\n",
    "stheta = -1\n",
    "num_maps_to_train = 5\n",
    "indices = [idx for idx,i in enumerate(map_names) if i in train_maps]\n",
    "save_path = 'SARSA_Multiple_training/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "counter = 0\n",
    "inference_file = None\n",
    "reward_file=None\n",
    "collision_file=None\n",
    "map_path_subset = [all_map_paths[i] for i in indices]\n",
    "map_centers_subset = [map_centers[i] for i in indices]\n",
    "map_names_subset = [map_names[i] for i in indices]\n",
    "\n",
    "simulator = F1Tenth_navigation(gym_env_code=gym_env_code, num_agents=num_agents, map_path=map_path_subset, map_ext=map_ext, sx=sx, sy=sy, stheta=stheta, map_centers_file=map_centers_subset, save_path=save_path, track_name=map_names_subset, inference=inference_file,reward_file=reward_file,collision_file=collision_file)\n",
    "simulator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/praneeth/shared_f1_tenth /'\n",
    "folder_name= 'Nuerburgring'\n",
    "folder_BTSP = 'Silverstone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/praneeth/shared_f1_tenth /'\n",
    "reward_file_BTSP = f'{path}Weights_BTSP/{folder_BTSP}/rewards.npy'\n",
    "time_file_BTSP = f'{path}Weights_BTSP/{folder_BTSP}/times.npy'\n",
    "path_BTSP = f'{path}Weights_BTSP/{folder_BTSP}'\n",
    "\n",
    "reward_file_normal = f'{path}Weights/{folder_name}/rewards.npy'\n",
    "time_file_normal = f'{path}Weights/{folder_name}/times.npy'\n",
    "path_normal = f'{path}Weights/{folder_name}'\n",
    "\n",
    "episode_num=[0]\n",
    "for file in os.listdir(path_BTSP):\n",
    "    if file.startswith('weights'):\n",
    "        episode_num.append(int(int(file.split('_')[1].split('.')[0])/1000))\n",
    "\n",
    "episode_num = sorted(episode_num) \n",
    "\n",
    "reward = np.load(reward_file_BTSP)\n",
    "times= np.load(time_file_BTSP)\n",
    "\n",
    "reward_normal = np.load(reward_file_normal)\n",
    "times_normal= np.load(time_file_normal)[:episode_num[-1]+1]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4))\n",
    "# ax[0].plot(list(range(episode_num[-1]+1)),reward/10000,label='HCL')\n",
    "# # ax[0].set_title('Reward Vs Trials')\n",
    "# ax[0].set_xlabel('Number of Trials ($10^3$)')\n",
    "# ax[0].set_ylabel('Reward ($10^4$)') \n",
    "ax.plot(list(range(episode_num[-1]+1)),times/1000,label='HCL')\n",
    "# ax[1].set_title('Time Vs Trials')\n",
    "ax.set_xlabel('Number of Trials ($10^3$)')\n",
    "ax.set_ylabel('Time to Collisions ($10^3$) s')\n",
    "\n",
    "# ax.plot(list(range(episode_num[-1]+1)),reward_normal[:episode_num[-1]+1]/10000,label='SARSA($\\lambda$)')\n",
    "ax.plot(list(range(episode_num[-1]+1)),times_normal/1000,label='SARSA($\\lambda$)')\n",
    "ax.legend()\n",
    "ax.legend()\n",
    "\n",
    "# fig.suptitle('BTSP')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/praneeth/shared_f1_tenth /'\n",
    "reward_file_normal = f'{path}Weights/{folder_name}/rewards.npy'\n",
    "time_file_normal = f'{path}Weights/{folder_name}/times.npy'\n",
    "path_normal = f'{path}Weights/{folder_name}'\n",
    "episode_num=[0]\n",
    "for file in os.listdir(path):\n",
    "    if file.startswith('weights'):\n",
    "        episode_num.append(int(int(file.split('_')[1].split('.')[0])/1000))\n",
    "\n",
    "episode_num = sorted(episode_num) \n",
    "\n",
    "reward = np.load(reward_file_normal)\n",
    "times= np.load(time_file_normal)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,4))\n",
    "ax[0].plot(list(range(episode_num[-1]+1)[:21]),reward[:21]/10000)\n",
    "ax[0].set_title('Reward Vs Collisions')\n",
    "ax[0].set_xlabel('Number of collisions ($10^3$)')\n",
    "ax[0].set_ylabel('Reward ($10^4$)') \n",
    "ax[1].plot(list(range(episode_num[-1]+1)[:21]),times[:21]/1000)\n",
    "ax[1].set_title('Time Vs Collisions')\n",
    "ax[1].set_xlabel('Number of collisions ($10^3$)')\n",
    "ax[1].set_ylabel('Time to collision ($10^3$) s')\n",
    "fig.suptitle('SARSA($\\lambda$)')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
